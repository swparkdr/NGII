
import requests
from bs4 import BeautifulSoup
import urllib.parse

# í¬ë¡¤ë§í•  ë²•ë ¹ëª… ë¦¬ìŠ¤íŠ¸
law_names = [
    "ê³µê°„ì •ë³´ì˜ êµ¬ì¶• ë° ê´€ë¦¬ ë“±ì— ê´€í•œ ë²•ë¥ ",
    "ê³µê°„ì •ë³´ì˜ êµ¬ì¶• ë° ê´€ë¦¬ ë“±ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹",
    "ê³µê°„ì •ë³´ì˜ êµ¬ì¶• ë° ê´€ë¦¬ ë“±ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™",
    "êµ­ê°€ê³µê°„ì •ë³´ ê¸°ë³¸ë²•",
    "êµ­ê°€ê³µê°„ì •ë³´ ê¸°ë³¸ë²• ì‹œí–‰ë ¹",
    "ê³µê°„ì •ë³´ì‚°ì—… ì§„í¥ë²•",
    "ê³µê°„ì •ë³´ì‚°ì—… ì§„í¥ë²• ì‹œí–‰ë ¹",
    "ê³µê°„ì •ë³´ì‚°ì—… ì§„í¥ë²• ì‹œí–‰ê·œì¹™"
]

base_url = "https://www.law.go.kr"
search_url = "https://www.law.go.kr/lsSc.do?eventGubun=060101&query="

law_dict = {}

for law in law_names:
    encoded_query = urllib.parse.quote(law)
    url = search_url + encoded_query
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    # 'ë²•ë ¹ëª…'ì„ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” a íƒœê·¸ ì°¾ê¸°
    law_link = soup.find("a", text=law)

    if law_link:
        href = law_link['href']
        # href ì˜ˆì‹œ: "javascript:lawView('20341','');"
        if "lawView" in href:
            mst_id = href.split("'")[1]  # lawView('20341',''); ì—ì„œ 20341 ì¶”ì¶œ
            law_dict[law] = mst_id
            print(f"âœ… {law} â†’ mst_id: {mst_id}")
        else:
            print(f"âŒ {law} â†’ mst_id ì¶”ì¶œ ì‹¤íŒ¨ (lawView í•¨ìˆ˜ ì—†ìŒ)")
    else:
        print(f"âŒ {law} â†’ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

print("\nğŸ” ìµœì¢… law_dict:")
print(law_dict)
